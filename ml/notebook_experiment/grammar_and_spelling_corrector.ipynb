{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar & Spelling Corrector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "The public version of the Corpus of Linguistic Acceptability (CoLA) dataset contains 9,594 sentences from training and development sets, which are used to assess the grammatical correctness of sentences. The dataset utilized in this project is derived from the original CoLA dataset, with grammatically correct sentences removed.\n",
    "\n",
    "##### Dataset download links:\n",
    "- in_domain_train.tsv:- https://github.com/nyu-mll/CoLA-baselines/blob/master/acceptability_corpus/cola_public/raw/in_domain_train.tsv\n",
    "- in_domain_dev.tsv:- https://github.com/nyu-mll/CoLA-baselines/blob/master/acceptability_corpus/cola_public/raw/in_domain_dev.tsv\n",
    "\n",
    "This revision clarifies the purpose of the dataset and improves the overall readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As you eat the most, you want the least.</td>\n",
       "      <td>As you eat more, you desire less.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The more you would want, the less you would eat.</td>\n",
       "      <td>The more you desire, the less you eat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I demand that the more John eat, the more he p...</td>\n",
       "      <td>I demand that the more John eats, the more he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The more does Bill smoke, the more Susan hates...</td>\n",
       "      <td>The more Bill smokes, the more Susan hates him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who does John visit Sally because he likes?</td>\n",
       "      <td>Whom does John visit because he likes Sally?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0           As you eat the most, you want the least.   \n",
       "1   The more you would want, the less you would eat.   \n",
       "2  I demand that the more John eat, the more he p...   \n",
       "3  The more does Bill smoke, the more Susan hates...   \n",
       "4        Who does John visit Sally because he likes?   \n",
       "\n",
       "                                         target_text  \n",
       "0                As you eat more, you desire less.    \n",
       "1           The more you desire, the less you eat.    \n",
       "2  I demand that the more John eats, the more he ...  \n",
       "3  The more Bill smokes, the more Susan hates him.    \n",
       "4     Whom does John visit because he likes Sally?    "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(r'../data/grammar_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input_text     0\n",
       "target_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>516</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>As you eat the most, you want the least.</td>\n",
       "      <td>The lions ate the meat raw.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      input_text  \\\n",
       "count                                        516   \n",
       "unique                                       516   \n",
       "top     As you eat the most, you want the least.   \n",
       "freq                                           1   \n",
       "\n",
       "                          target_text  \n",
       "count                             516  \n",
       "unique                            507  \n",
       "top     The lions ate the meat raw.    \n",
       "freq                                2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/gmsgrqy5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2b72e51cb30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode='disabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 412\n",
      "Test dataset size: 104\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=r\"..\\data\\grammar_data.csv\")\n",
    "split_dataset = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer= AutoTokenizer.from_pretrained('t5-small')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize inputs and targets\n",
    "    inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    targets = tokenizer(examples['target_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    \n",
    "    # Adjust labels for training (replace padding token ID with -100)\n",
    "    labels = [\n",
    "        [(label if label != tokenizer.pad_token_id else -100) for label in labels]\n",
    "        for labels in targets[\"input_ids\"]\n",
    "    ]\n",
    "    \n",
    "    # Add labels to inputs for training\n",
    "    inputs[\"labels\"] = labels\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "tokenized_train_dataset= train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset= test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bill pushed Harry off the sofa repeatedly for hours.', 'Sharon entered the room.', 'The bottle was drained of its liquid.', 'Sam took the ball out of the basket.', 'The more pictures of himself that appear in the news, the more likely John is to get arrested.']\n"
     ]
    }
   ],
   "source": [
    "#verifying the correctness of preprocessing\n",
    "decoded_refs = []\n",
    "for label in tokenized_test_dataset['labels']:\n",
    "    # Replace -100 with pad_token_id to make it decodable\n",
    "    filtered_label = [token if token >= 0 else tokenizer.pad_token_id for token in label]\n",
    "    decoded_refs.append(tokenizer.decode(filtered_label, skip_special_tokens=True))\n",
    "\n",
    "print(decoded_refs[:5])  # Print a few decoded references for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuining the T5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Finding the best Lerning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import TrainingArguments, Trainer, AutoModelForSeq2SeqLM\\n\\nlearning_rates = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\\nepochs = [1, 2, 3, 5]  # Different values of epochs to test\\n\\nresults = []  # To store learning rate, epoch, and evaluation loss\\n\\nfor lr in learning_rates:\\n    for epoch in epochs:\\n        # Initialize model for each iteration\\n        model = AutoModelForSeq2SeqLM.from_pretrained(\\'t5-base\\')\\n\\n        # Update training arguments\\n        lr_range_args = TrainingArguments(\\n            output_dir=f\"./lr_test_lr{lr}_epoch{epoch}\",\\n            fp16=True,\\n            per_device_train_batch_size=8,\\n            per_device_eval_batch_size=8,\\n            num_train_epochs=epoch,\\n            logging_steps=5,\\n            save_steps=0,  # No saving\\n            learning_rate=lr,\\n        )\\n        # Initialize Trainer\\n        trainer = Trainer(\\n            model=model,\\n            args=lr_range_args,\\n            train_dataset=tokenized_train_dataset,\\n            eval_dataset=tokenized_test_dataset,\\n            processing_class=tokenizer,\\n        )\\n        # Train and evaluate\\n        trainer.train()\\n        metrics = trainer.evaluate()\\n        results.append((lr, epoch, metrics[\\'eval_loss\\']))\\n        '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoModelForSeq2SeqLM\n",
    "\n",
    "learning_rates = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "epochs = [1, 2, 3, 5]  # Different values of epochs to test\n",
    "\n",
    "results = []  # To store learning rate, epoch, and evaluation loss\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for epoch in epochs:\n",
    "        # Initialize model for each iteration\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "\n",
    "        # Update training arguments\n",
    "        lr_range_args = TrainingArguments(\n",
    "            output_dir=f\"./lr_test_lr{lr}_epoch{epoch}\",\n",
    "            fp16=True,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=epoch,\n",
    "            logging_steps=5,\n",
    "            save_steps=0,  # No saving\n",
    "            learning_rate=lr,\n",
    "        )\n",
    "        # Initialize Trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=lr_range_args,\n",
    "            train_dataset=tokenized_train_dataset,\n",
    "            eval_dataset=tokenized_test_dataset,\n",
    "            processing_class=tokenizer,\n",
    "        )\n",
    "        # Train and evaluate\n",
    "        trainer.train()\n",
    "        metrics = trainer.evaluate()\n",
    "        results.append((lr, epoch, metrics['eval_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Save results\\nresults_df = pd.DataFrame(results, columns=[\"Learning Rate\", \"Epochs\", \"Eval Loss\"])\\nresults_df.to_csv(\"lr_epoch_results.csv\", index=False)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save results\n",
    "results_df = pd.DataFrame(results, columns=[\"Learning Rate\", \"Epochs\", \"Eval Loss\"])\n",
    "results_df.to_csv(\"lr_epoch_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\npivot_table = results_df.pivot(\"Learning Rate\", \"Epochs\", \"Eval Loss\")\\n\\nplt.figure(figsize=(10, 6))\\nsns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis\")\\nplt.title(\"Evaluation Loss for Different Learning Rates and Epochs\")\\nplt.xlabel(\"Epochs\")\\nplt.ylabel(\"Learning Rate\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot_table = results_df.pivot(\"Learning Rate\", \"Epochs\", \"Eval Loss\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"viridis\")\n",
    "plt.title(\"Evaluation Loss for Different Learning Rates and Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The learning rate around 1e-5 or 1e-4 seems to be optimal since the loss decreases consistently.\n",
    "- Hence I'll use the lower bound of the suggested range, i.e. 1e-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the training arguments\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5_corrector\",\n",
    "    run_name= \"grammar_corrector\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "\n",
    "model= AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "data_collector= DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer= Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7361f48a84b446a7a80618cbdf60daa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6762, 'grad_norm': 8.218499183654785, 'learning_rate': 9.047619047619047e-07, 'epoch': 0.29}\n",
      "{'loss': 1.6476, 'grad_norm': 9.330354690551758, 'learning_rate': 8.095238095238095e-07, 'epoch': 0.57}\n",
      "{'loss': 1.6445, 'grad_norm': 11.684385299682617, 'learning_rate': 7.142857142857143e-07, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c165a148784bffa5117d95e8227074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.601723313331604, 'eval_runtime': 190.2338, 'eval_samples_per_second': 0.547, 'eval_steps_per_second': 0.047, 'epoch': 1.0}\n",
      "{'loss': 1.6168, 'grad_norm': 8.2537260055542, 'learning_rate': 6.19047619047619e-07, 'epoch': 1.14}\n",
      "{'loss': 1.6556, 'grad_norm': 8.574418067932129, 'learning_rate': 5.238095238095238e-07, 'epoch': 1.43}\n",
      "{'loss': 1.5864, 'grad_norm': 9.601585388183594, 'learning_rate': 4.285714285714285e-07, 'epoch': 1.71}\n",
      "{'loss': 1.4564, 'grad_norm': 11.905344009399414, 'learning_rate': 3.333333333333333e-07, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643ef2f5dcc045a7b9fbffdd124c08c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5402783155441284, 'eval_runtime': 215.0359, 'eval_samples_per_second': 0.484, 'eval_steps_per_second': 0.042, 'epoch': 2.0}\n",
      "{'loss': 1.6306, 'grad_norm': 8.841704368591309, 'learning_rate': 2.3809523809523806e-07, 'epoch': 2.29}\n",
      "{'loss': 1.4687, 'grad_norm': 10.055954933166504, 'learning_rate': 1.4285714285714285e-07, 'epoch': 2.57}\n",
      "{'loss': 1.4933, 'grad_norm': 12.520830154418945, 'learning_rate': 4.7619047619047613e-08, 'epoch': 2.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cd07b8dd8d48e6a252c4540c7d0b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5202873945236206, 'eval_runtime': 220.2286, 'eval_samples_per_second': 0.472, 'eval_steps_per_second': 0.041, 'epoch': 3.0}\n",
      "{'train_runtime': 13226.0786, 'train_samples_per_second': 0.093, 'train_steps_per_second': 0.008, 'train_loss': 1.5859757832118444, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=105, training_loss=1.5859757832118444, metrics={'train_runtime': 13226.0786, 'train_samples_per_second': 0.093, 'train_steps_per_second': 0.008, 'total_flos': 188167988183040.0, 'train_loss': 1.5859757832118444, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(tokenized_test_dataset['input_ids'])\n",
    "attention_mask = torch.tensor(tokenized_test_dataset['attention_mask'])\n",
    "\n",
    "# Obtained predictions from the trained model using beam search\n",
    "predictions = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    num_beams=7, \n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding predictions\n",
    "decoded_predictions = [\n",
    "    tokenizer.decode(pred, skip_special_tokens=True)\n",
    "    for pred in predictions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding references, replacing -100 with pad_token_id for valid decoding\n",
    "decoded_refs = []\n",
    "for label in tokenized_test_dataset['labels']:\n",
    "    # Replaced -100 with pad_token_id for decoding\n",
    "    filtered_label = [token if token >= 0 else tokenizer.pad_token_id for token in label]\n",
    "    decoded_refs.append(tokenizer.decode(filtered_label, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from symspellpy import SymSpell\n",
    "# Initialize SymSpell for spelling correction\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "\n",
    "# Load dictionary files for SymSpell\n",
    "# Replace these paths with the actual paths to your dictionary files\n",
    "dictionary_path = r\"..\\ml\\data\\en-80k.txt\"\n",
    "\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SymSpell for spelling correction\n",
    "def correct_spelling(texts, sym_spell):\n",
    "    corrected_texts = []\n",
    "    for text in texts:\n",
    "        suggestion = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
    "        corrected_texts.append(suggestion[0].term if suggestion else text)\n",
    "    return corrected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LanguageTool for grammar correction\n",
    "from language_tool_python import LanguageTool\n",
    "tool = LanguageTool('en')\n",
    "\n",
    "def correct_grammar(texts):\n",
    "    corrected_texts = []\n",
    "    for text in texts:\n",
    "        matches = tool.check(text)\n",
    "        corrected_text = tool.correct(text)\n",
    "        corrected_texts.append(corrected_text)\n",
    "    return corrected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct predictions\n",
    "spelling_corrected = correct_spelling(decoded_predictions, sym_spell)\n",
    "final_corrected = correct_grammar(spelling_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Prediction: Harry off the sofa for hours bill pushed harry off the sofa for hours\n",
      "Reference: Bill pushed Harry off the sofa repeatedly for hours.\n",
      "\n",
      "Corrected Prediction: Sharon came the room\n",
      "Reference: Sharon entered the room.\n",
      "\n",
      "Corrected Prediction: Drained the liquid free the bottle drained the liquid free\n",
      "Reference: The bottle was drained of its liquid.\n",
      "\n",
      "Corrected Prediction: Sam gave the ball out of the basket\n",
      "Reference: Sam took the ball out of the basket.\n",
      "\n",
      "Corrected Prediction: The more pictures of himself appear in the news the more likely john is to get arrested\n",
      "Reference: The more pictures of himself that appear in the news, the more likely John is to get arrested.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions to references\n",
    "for corrected_pred, ref in zip(final_corrected[:5], decoded_refs[:5]):\n",
    "    print(f\"Corrected Prediction: {corrected_pred}\")\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\jaysh\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--sacrebleu\\28676bf65b4f88b276df566e48e603732d0b4afd237603ebdf92acaacf5be99b (last modified on Wed Jan  8 15:27:06 2025) since it couldn't be found locally at evaluate-metric--sacrebleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd47348655c040b192fc8dbef2a3056b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OverflowError",
     "evalue": "can't convert negative int to unsigned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[0;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_test_dataset)\n\u001b[1;32m----> 8\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m decoded_refs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     [tokenizer\u001b[38;5;241m.\u001b[39mdecode([label \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m tokenized_test_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Compute BLEU score\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaysh\\All_Projects\\Current_Projects\\CustomEmail_A_Personalized_Email_Sender\\customemail\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3804\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[1;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[0;32m   3780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3781\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3784\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3785\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[0;32m   3788\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m-> 3804\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3807\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3810\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[0;32m   3811\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\jaysh\\All_Projects\\Current_Projects\\CustomEmail_A_Personalized_Email_Sender\\customemail\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3843\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m   3840\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m   3841\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[1;32m-> 3843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3847\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jaysh\\All_Projects\\Current_Projects\\CustomEmail_A_Personalized_Email_Sender\\customemail\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:655\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    654\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[1;32m--> 655\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    658\u001b[0m     clean_up_tokenization_spaces\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[0;32m    661\u001b[0m )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[1;31mOverflowError\u001b[0m: can't convert negative int to unsigned"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "metric = load(\"sacrebleu\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "\n",
    "decoded_refs = [\n",
    "    [tokenizer.decode([label for label in labels if label >= 0], skip_special_tokens=True)]\n",
    "    for labels in tokenized_test_dataset['labels']\n",
    "]\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_score = metric.compute(predictions=decoded_preds, references=decoded_refs)\n",
    "print(bleu_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customemail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
